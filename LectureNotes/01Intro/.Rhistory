# Pad state and county
monitor_dt[, `:=`(
st_fips = as.character(state),
cty_fips = as.character(county)
)]
monitor_dt[, st_fips := str_pad(st_fips, 2, "left", 0)]
monitor_dt[, cty_fips := str_pad(cty_fips, 3, "left", 0)]
# Create an ID for CBG and county
monitor_dt[, fips := paste0(st_fips, cty_fips)]
# Take max of monitors within year-county
cty_dt <- monitor_dt[, .(
cty_dv = max(pm_mean, na.rm = T)
), by = .(year, fips)]
# Join 2005 data with the county shapefiles
left_join(
cty_shp,
cty_dt[year == 2005, .(fips, cty_dv)]
)
# Load and process monitor data --------------------------------------------------------------------
# Load monitor-level data
monitor_dt <- dir_data %>%
paste0("Processed/MonitorLevel.dta") %>%
read_dta() %>%
data.table()
# Keep 88101 w/ events
monitor_dt <- monitor_dt[dataset == "AQS_88101" & dataset2 == "wEvents"]
# Drop monitors missing state, county, or pm_mean
monitor_dt <- monitor_dt[!(is.na(state) | is.na(county) | is.na(pm_mean))]
# Pad state and county
monitor_dt[, `:=`(
st_fips = as.character(state),
cty_fips = as.character(county)
)]
monitor_dt[, st_fips := str_pad(st_fips, 2, "left", 0)]
monitor_dt[, cty_fips := str_pad(cty_fips, 3, "left", 0)]
# Create an ID for CBG and county
monitor_dt[, fips := paste0(st_fips, cty_fips)]
# Take max of monitors within year-county
cty_dt <- monitor_dt[, .(
cty_dv = max(pm_mean, na.rm = T)
), by = .(year, fips)]
# Join 2005 data with the county shapefiles
left_join(
cty_shp,
cty_dt[year == 2005, .(fips, cty_dv)],
by = "fips"
)
# Load and process monitor data --------------------------------------------------------------------
# Load monitor-level data
monitor_dt <- dir_data %>%
paste0("Processed/MonitorLevel.dta") %>%
read_dta() %>%
data.table()
# Keep 88101 w/ events
monitor_dt <- monitor_dt[dataset == "AQS_88101" & dataset2 == "wEvents"]
# Drop monitors missing state, county, or pm_mean
monitor_dt <- monitor_dt[!(is.na(state) | is.na(county) | is.na(pm_mean))]
# Pad state and county
monitor_dt[, `:=`(
st_fips = as.character(state),
cty_fips = as.character(county)
)]
monitor_dt[, st_fips := str_pad(st_fips, 2, "left", 0)]
monitor_dt[, cty_fips := str_pad(cty_fips, 3, "left", 0)]
# Create an ID for CBG and county
monitor_dt[, fips := paste0(st_fips, cty_fips)]
# Take max of monitors within year-county
cty_dt <- monitor_dt[, .(
cty_dv = max(pm_mean, na.rm = T)
), by = .(year, fips)]
# Join 2005 data with the county shapefiles
cty_shp <- left_join(
cty_shp,
cty_dt[year == 2005, .(fips, cty_dv)],
by = "fips"
)
cty_shp
st_write(
cty_shp,
dir_out %>% paste0("us_states/us_states.shp"),
delete_layer = T
)
# Setup --------------------------------------------------------------------------------------------
# Options
options(stringsAsFactors = F)
# Packages
library(pacman)
# p_install_gh("dkahle/ggmap")
p_load(
maps, ggmap, raster, sf,
parallel,
tidyverse, haven, stringr,
data.table, lubridate, magrittr
)
# Directories
dir_box  <- "~/Box/PredictingAQ/"
dir_db   <- "~/Dropbox/Research/MyProjects/Air pollution modeling/"
dir_vdna <- dir_db %>% paste0("Data/vanDonkelaar/")
dir_vdg  <- dir_box %>% paste0("DataRaw/VD/vanDonkelaarGlobal/")
dir_di   <- dir_db %>% paste0("Data/DiEtAl2018/US_PM25_NewModel/")
dir_out  <- dir_db %>% paste0("Data/ForMaps/")
dir_st   <- "~/Dropbox/Research/MyProjects/DataGeneral/cb_2013_us_state_500k/"
dir_cty  <- "~/Dropbox/Research/MyProjects/DataGeneral/tl_2015_us_county/"
dir_data <- dir_db %>% paste0("Data/")
# Load US state shapefile --------------------------------------------------------------------------
# Load it
state_shp <- st_read(dir_st, "cb_2013_us_state_500k") %>%
filter(!(NAME %in% c(
"Alaska",
"American Samoa",
"Commonwealth of the Northern Mariana Islands",
"Guam",
"Hawaii",
"Puerto Rico",
"United States Virgin Islands"
)))
# Take union
us_shp <- st_union(state_shp) %>% as_Spatial()
# Save state shapefile -----------------------------------------------------------------------------
# Save it
st_write(
state_shp %>% select(NAME, STATEFP, STUSPS),
dir_out %>% paste0("us_states/us_states.shp"),
delete_layer = T
)
# Load US county shapefile -------------------------------------------------------------------------
# Load it
cty_shp <- st_read(dir_cty, "tl_2015_us_county") %>%
filter(STATEFP %in% str_pad(state.fips$fips, 2, "left", 0)) %>%
transmute(
st_fips = STATEFP,
cty_fips = COUNTYFP,
fips = GEOID
)
# Load and process monitor data --------------------------------------------------------------------
# Load monitor-level data
monitor_dt <- dir_data %>%
paste0("Processed/MonitorLevel.dta") %>%
read_dta() %>%
data.table()
# Keep 88101 w/ events
monitor_dt <- monitor_dt[dataset == "AQS_88101" & dataset2 == "wEvents"]
# Drop monitors missing state, county, or pm_mean
monitor_dt <- monitor_dt[!(is.na(state) | is.na(county) | is.na(pm_mean))]
# Pad state and county
monitor_dt[, `:=`(
st_fips = as.character(state),
cty_fips = as.character(county)
)]
monitor_dt[, st_fips := str_pad(st_fips, 2, "left", 0)]
monitor_dt[, cty_fips := str_pad(cty_fips, 3, "left", 0)]
# Create an ID for CBG and county
monitor_dt[, fips := paste0(st_fips, cty_fips)]
# Take max of monitors within year-county
cty_dt <- monitor_dt[, .(
cty_dv = max(pm_mean, na.rm = T)
), by = .(year, fips)]
# Join 2005 data with the county shapefiles
cty_shp <- left_join(
cty_shp,
cty_dt[year == 2005, .(fips, cty_dv)],
by = "fips"
)
# Save
st_write(
cty_shp,
dir_out %>% paste0("us_counties/us_counties.shp"),
delete_layer = T
)
cty_dt
cty_dt[year == 2005, cty_dv] %>% is.na %>% mean()
cty_dt[year == 2005, cty_dv] %>% is.na %>% table
cty_shp$cty_dv %>% is.na %>% table
cty_shp$cty_dv %>% summary
cty_shp$cty_dv %>% is_greater_than(15) %>% summary
cty_shp$cty_dv %>% summary
cty_shp %<>% mutate(cty_dv = ifelse(is.na(cty_dv), 1.5, cty_dv))
cty_shp
st_write(
cty_shp,
dir_out %>% paste0("us_counties/us_counties.shp"),
delete_layer = T
)
cty_dt[year == 2005, cty_dv] %>% quantiles(seq(0,1,0.05))
cty_dt[year == 2005, cty_dv] %>% quantile(seq(0,1,0.05))
cty_dt[year == 2005, cty_dv] %>% quantile(seq(0,1,0.05))
# Load and process monitor data --------------------------------------------------------------------
# Load monitor-level data
monitor_dt <- dir_data %>%
paste0("Processed/MonitorLevel.dta") %>%
read_dta() %>%
data.table()
# Keep 88101 w/ events
monitor_dt <- monitor_dt[dataset == "AQS_88101" & dataset2 == "wEvents"]
# Drop monitors missing state, county, or pm_mean
monitor_dt <- monitor_dt[!(is.na(state) | is.na(county) | is.na(pm_mean))]
# Pad state and county
monitor_dt[, `:=`(
st_fips = as.character(state),
cty_fips = as.character(county)
)]
monitor_dt[, st_fips := str_pad(st_fips, 2, "left", 0)]
monitor_dt[, cty_fips := str_pad(cty_fips, 3, "left", 0)]
# Create an ID for CBG and county
monitor_dt[, fips := paste0(st_fips, cty_fips)]
# Take max of monitors within year-county
cty_dt <- monitor_dt[, .(
cty_dv = max(pm_mean, na.rm = T)
), by = .(year, fips)]
# Join 2005 data with the county shapefiles
cty_shp <- left_join(
cty_shp,
cty_dt[year == 2005, .(fips, cty_dv)],
by = "fips"
)
# Replace NA with 1.5 (the min on the color scale)
cty_shp %<>% mutate(cty_dv = ifelse(is.na(cty_dv), 1.5, cty_dv))
cty_shp %<>% mutate(cty_dv = ifelse(cty_dv > 17.5, 17.5, cty_dv))
# Save
st_write(
cty_shp,
dir_out %>% paste0("us_counties/us_counties.shp"),
delete_layer = T
)
# Load US county shapefile -------------------------------------------------------------------------
# Load it
cty_shp <- st_read(dir_cty, "tl_2015_us_county") %>%
filter(STATEFP %in% str_pad(state.fips$fips, 2, "left", 0)) %>%
transmute(
st_fips = STATEFP,
cty_fips = COUNTYFP,
fips = GEOID
)
# Load and process monitor data --------------------------------------------------------------------
# Load monitor-level data
monitor_dt <- dir_data %>%
paste0("Processed/MonitorLevel.dta") %>%
read_dta() %>%
data.table()
# Keep 88101 w/ events
monitor_dt <- monitor_dt[dataset == "AQS_88101" & dataset2 == "wEvents"]
# Drop monitors missing state, county, or pm_mean
monitor_dt <- monitor_dt[!(is.na(state) | is.na(county) | is.na(pm_mean))]
# Pad state and county
monitor_dt[, `:=`(
st_fips = as.character(state),
cty_fips = as.character(county)
)]
monitor_dt[, st_fips := str_pad(st_fips, 2, "left", 0)]
monitor_dt[, cty_fips := str_pad(cty_fips, 3, "left", 0)]
# Create an ID for CBG and county
monitor_dt[, fips := paste0(st_fips, cty_fips)]
# Take max of monitors within year-county
cty_dt <- monitor_dt[, .(
cty_dv = max(pm_mean, na.rm = T)
), by = .(year, fips)]
# Join 2005 data with the county shapefiles
cty_shp <- left_join(
cty_shp,
cty_dt[year == 2005, .(fips, cty_dv)],
by = "fips"
)
# Replace NA with 1.5 (the min on the color scale)
cty_shp %<>% mutate(cty_dv = ifelse(is.na(cty_dv), 1.5, cty_dv))
cty_shp %<>% mutate(cty_dv = ifelse(cty_dv > 17.5, 17.5, cty_dv))
# Save
st_write(
cty_shp,
dir_out %>% paste0("us_counties/us_counties.shp"),
delete_layer = T
)
# Setup ----------------------------------------------------------------------------------
# Options
options(stringsAsFactors = F)
# Packages
library(pacman)
p_load(
ggplot2, ggthemes, latex2exp, Cairo, viridis,
maps, sf, parallel,
lfe, rpart, party, glmnet,
tidyverse, haven, data.table, magrittr
)
# Directories
dir_project  <- "~/Dropbox/Research/MyProjects/Air pollution modeling/"
dir_data     <- dir_project %>% paste0("Data/")
dir_figures  <- dir_project %>% paste0("Figures/")
# Load PM data ---------------------------------------------------------------------------
# Load CBG dataset
pm_dt <- dir_data %>%
paste0("PM_all_wide.dta") %>%
read_dta() %>%
data.table()
# Setup ----------------------------------------------------------------------------------
# Options
options(stringsAsFactors = F)
# Packages
library(pacman)
p_load(
ggplot2, ggthemes, latex2exp, Cairo, viridis,
maps, sf, parallel,
lfe, rpart, party, glmnet,
kableExtra,
tidyverse, haven, data.table, magrittr
)
# Directories
dir_project  <- "~/Dropbox/Research/MyProjects/Air pollution modeling/"
dir_data     <- dir_project %>% paste0("Data/")
dir_figures  <- dir_project %>% paste0("Figures/")
dir_tables   <- dir_project %>% paste0("Tables/")
# Functions: Format percentages and comma numbers ----------------------------------------
form_pct <- function(x, rnd = 2) {
x %>% round(rnd) %>% multiply_by(100) %>% format(nsmall = rnd - 2)
}
form_com <- function(x, rnd = 0) x %>% round(rnd) %>% format(big.mark = ",")
# Load PM data ---------------------------------------------------------------------------
# Load CBG dataset
pm_dt <- dir_data %>%
paste0("PM_all_wide.dta") %>%
read_dta() %>%
data.table()
# Clean data: CBG PM2.5 data -------------------------------------------------------------
# Keep 2001-2017
pm_dt <- pm_dt[between(year, 2001, 2017)]
# Create id_cbg and fips to match other files
# (Pad state and county to match across datasets)
pm_dt[, id_cbg := paste(
str_pad(state, 2, "left", 0),
str_pad(county, 3, "left", 0),
tract,
blockgroup
)]
pm_dt[, fips := paste0(
str_pad(state, 2, "left", 0),
str_pad(county, 3, "left", 0)
)]
# # Drop unwanted geographic variables
# pm_dt[, c("state", "countyname", "county", "tract", "blockgroup") := NULL]
# For number-of-monitors variables: change NAs to 0s
pm_dt[is.na(nMonitors_AQSnoEvents), nMonitors_AQSnoEvents := 0]
pm_dt[is.na(nMonitors_AQSwEvents), nMonitors_AQSwEvents := 0]
pm_dt[is.na(nMonitors_IMPROVE), nMonitors_IMPROVE := 0]
# Keep desired variables
pm_dt <- pm_dt[, .(
id_cbg, fips, airRegion, year,
state, countyname, county, tract, blockgroup,
pm_AQSwEvents_3yr, pm_AQSwEvents_p98, pm_AQSnoEvents_3yr, pm_AQSnoEvents_p98,
pm_IMPROVE_3yr,
pm_vdna_3yr, pm_vdna_3yrOLD, pm_vdgAnnual, pm_vdg_3yr, pm_diAnnual, pm_di_3yr,
# naa97_ctyP_2005, naa97_ctyW_2005, naa97_ctyP_2011, naa97_ctyW_2011,
pop_total = popTotal,
pop_asian = popAsian,
pop_black = popBlack,
pop_other = popOther,
pop_white = popWhite,
pop_rural = popRural,
pop_urban = popUrban,
income_pc = incPerCap,
pop_under_5 = popAge0to4,
pop_over_65 = popAge65to66 + popAge67to69 + popAge70to74 + popAge75to79 +
popAge80to84 + popAge85plus,
pop_hs_less = popEduc0toGr8 + popEducGr8to12,
pop_acs = popEduc0toGr8 + popEducGr8to12 + popEducSomeColl +
popEducFinColl + popEducPost,
elev_min = minElev, elev_max = maxElev,
area = areaSqMile
)]
# Add share variables
pm_dt[, `:=`(
share_asian = pop_asian / pop_total,
share_black = pop_black / pop_total,
share_other = pop_other / pop_total,
share_white = pop_white / pop_total,
share_rural = pop_rural / pop_total,
share_urban = pop_urban / pop_total,
share_hs = pop_hs_less / pop_acs,
share_under_5 = pop_under_5 / pop_acs,
share_senior = pop_over_65 / pop_acs
)]
# Estimate error variance ----------------------------------------------------------------
# Create a dataset for prediction
se_dt <- pm_dt[, .(
pm_AQSwEvents_3yr, pm_AQSwEvents_p98, airRegion,
pm_vdna_3yr, pm_di_3yr,
e_vdna_3yr = pm_AQSwEvents_3yr - pm_vdna_3yr,
e_di_3yr = pm_AQSwEvents_3yr - pm_di_3yr,
pop_total, share_white, share_rural,
elev_max, elev_min, area
)] %>% na.omit()
# Regress estimates' errors on a set of covariates
se_di <- lm(
e_di_3yr ~
# pm_AQSwEvents_3yr + pm_AQSwEvents_p98 +
pm_di_3yr +
pop_total + share_white + share_rural +
elev_max + elev_min + area,
data = se_dt
)
se_vdna <- lm(
e_vdna_3yr ~
# pm_AQSwEvents_3yr + pm_AQSwEvents_p98 +
pm_vdna_3yr +
pop_total + share_white + share_rural +
elev_max + elev_min + area,
data = se_dt
)
# Regress estimates' squared errors on a set of covariates
v_di <- lm(
e_di_3yr^2 ~
# pm_AQSwEvents_3yr + pm_AQSwEvents_p98 +
pm_di_3yr +
pop_total + share_white + share_rural +
elev_max + elev_min + area,
data = se_dt
)
v_vdna <- lm(
e_vdna_3yr^2 ~
# pm_AQSwEvents_3yr + pm_AQSwEvents_p98 +
pm_vdna_3yr +
pop_total + share_white + share_rural +
elev_max + elev_min + area,
data = se_dt
)
# Get predicted error and prediction interval for observations
p_di <- predict(
object = se_di,
newdata = pm_dt,
se.fit = T,
weights = predict(
object = v_di,
newdata = pm_dt,
se.fit = F
),
interval = "prediction"
)
p_vdna <- predict(
object = se_vdna,
newdata = pm_dt,
se.fit = T,
weights = predict(
object = v_vdna,
newdata = pm_dt,
se.fit = F
),
interval = "prediction"
)
# Add the predictions and intervals
pm_dt[, `:=`(
pm_di_3yr_lb = pm_di_3yr + p_di$fit[,"lwr"],
pm_di_3yr_ub = pm_di_3yr + p_di$fit[,"upr"],
pm_vdna_3yr_lb = pm_vdna_3yr + p_vdna$fit[,"lwr"],
pm_vdna_3yr_ub = pm_vdna_3yr + p_vdna$fit[,"upr"]
)]
# Save object with prediction intervals, year, and geographic identifiers
write_dta(
data = pm_dt[, .(
year,
state,
county,
tract,
blockgroup,
pm_di_3yr_lb = pm_di_3yr + p_di$fit[,"lwr"],
pm_di_3yr_ub = pm_di_3yr + p_di$fit[,"upr"],
pm_vdna_3yr_lb = pm_vdna_3yr + p_vdna$fit[,"lwr"],
pm_vdna_3yr_ub = pm_vdna_3yr + p_vdna$fit[,"upr"]
)],
path = paste0(dir_data, "PredictionIntervals/piSatellite.dta")
)
v_di %>% summary
v_vd %>% summary
v_vdna %>% summary
e_vdna %>% summary
se_vdna %>% summary
se_di %>% summary
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
tmp <- data.frame(
year = 1999:2009,
count = c(
9, 8, 11, 12, 11, 13, 12, 9, 9, 7, 9,
6, 5, 5, 10, 8, 14, 10, 4, 8, 5, 6
),
type = rep(c("letters", "deaths"), each = 11)
)
ggplot(data = tmp, aes(x = year, y = count, color = type)) +
geom_path() +
geom_point(size = 4) +
xlab("Year") +
ylab("Count") +
scale_color_manual(
"",
labels = c("Deaths from spiders", "Letters in the winning spelling bee word"),
values = c(red_pink, "darkslategray")
) +
theme_pander(base_size = 17) +
theme(legend.position = "bottom")
xaringan:::inf_mr()
lm(deaths ~ letters, data = tmp) %>% summary
lm(deaths ~ letters, data = tmp) %>% summary %>% coef
?xaringan::moon_reader
?xaringan::moon_reader
install.packages(webshot)
install.packages('webshot')
library(webshot)
install_phantomjs()
setwd("Dropbox/UO/Teaching/EC421W19/LectureNotes/01Intro/")
dir()
webshot("01_intro.html", "01_intro.pdf")
